{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc37f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docker pull emacski/tensorflow-serving:latest-linux_arm64\n",
    "# docker run -t --rm -p 8501:8501 --mount type=bind,source=/tmp/model_name/,target=/models/model_name/ -e MODEL_NAME=model_name emacski/tensorflow-serving:latest-linux_arm64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "be652ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!docker start #como iniciar da  linha de comando\n",
    "!open --background -a Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e4920968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Hello from Docker!\r\n",
      "This message shows that your installation appears to be working correctly.\r\n",
      "\r\n",
      "To generate this message, Docker took the following steps:\r\n",
      " 1. The Docker client contacted the Docker daemon.\r\n",
      " 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub.\r\n",
      "    (arm64v8)\r\n",
      " 3. The Docker daemon created a new container from that image which runs the\r\n",
      "    executable that produces the output you are currently reading.\r\n",
      " 4. The Docker daemon streamed that output to the Docker client, which sent it\r\n",
      "    to your terminal.\r\n",
      "\r\n",
      "To try something more ambitious, you can run an Ubuntu container with:\r\n",
      " $ docker run -it ubuntu bash\r\n",
      "\r\n",
      "Share images, automate workflows, and more with a free Docker ID:\r\n",
      " https://hub.docker.com/\r\n",
      "\r\n",
      "For more examples and ideas, visit:\r\n",
      " https://docs.docker.com/get-started/\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!docker run hello-world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ed32a020",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!docker pull tensorflow/serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b1ae65dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# esse funciona para quem n tem m1\n",
    "#!docker pull tensorflow/serving:latest-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b7cb2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c16b820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "573f6b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.efficientnet_v2 import EfficientNetV2B0, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b59d1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EfficientNetV2B0(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dbe59c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/csamp/Documents/stack_ab'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "444ef35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n",
      "Predicted: [('n09332890', 'lakeside', 0.2955897), ('n09421951', 'sandbar', 0.24374594), ('n01855672', 'goose', 0.10379495)]\n"
     ]
    }
   ],
   "source": [
    "# img_path = 'tf_serving/lion.jpg'\n",
    "img_path = 'tf_serving/pexels-artūras-kokorevas-10547480.jpg'\n",
    "\n",
    "resized_height, resized_width = (250, 250)\n",
    "img = image.load_img(img_path, target_size=(height, width))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "preds = model.predict(x)\n",
    "# decode the results into a list of tuples (class, description, probability)\n",
    "# (one such list for each sample in the batch)\n",
    "\n",
    "print('Predicted:', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b511ce3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: effv2b0/1670550215/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: effv2b0/1670550215/assets\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "current_time = int(time.time())\n",
    "path = f\"effv2b0/{current_time}\"\n",
    "model.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5d588a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'effv2b0/1670550215'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cff6f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # how the folder should look like\n",
    "# ├── effv2b0\n",
    "# │ ├── 1670405165\n",
    "# │ │ ├── assets\n",
    "# │ │ ├── saved_model.pb\n",
    "# │ │ └── variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3966db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latest-linux_arm64: Pulling from emacski/tensorflow-serving\r\n",
      "Digest: sha256:37ae953d10a10f520fc7aca068c866f28a424894c47b1d06c8cec22e631e29be\r\n",
      "Status: Image is up to date for emacski/tensorflow-serving:latest-linux_arm64\r\n",
      "docker.io/emacski/tensorflow-serving:latest-linux_arm64\r\n"
     ]
    }
   ],
   "source": [
    "# esse funciona\n",
    "#!docker pull emacski/tensorflow-serving:latest-linux_arm64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8243eb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !docker run -t --rm -p 8501:8501 \\\n",
    "#     -v \"/Users/csamp/Documents/stack_ab/effv2b0/:/models/effv2b0/\" \\\n",
    "#     -e MODEL_NAME=effv2 \\\n",
    "#     emacski/tensorflow-serving:latest-linux_arm6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c5da3edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!docker run -p 8501:8501 --name tfserving_vgg16 --mount type=bind,source=vgg16/,target=vgg16/ -e MODEL_NAME=vgg16 -t tensorflow/serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d76863f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!docker run -p 8502:8502 --name ttfserving_vgg -v source=/Users/csamp/Documents/stack_ab/vgg16/,target=vgg16 -e MODEL_NAME=vgg16 -t emacski/tensorflow-serving:latest-linux_arm64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c1de367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/csamp/Documents/stack_ab'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "92aa4eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-09 01:44:49.693292: I external/tf_serving/tensorflow_serving/model_servers/server.cc:89] Building single TensorFlow model file config:  model_name: effv2b0 model_base_path: /models/effv2b0\n",
      "2022-12-09 01:44:49.694751: I external/tf_serving/tensorflow_serving/model_servers/server_core.cc:465] Adding/updating models.\n",
      "2022-12-09 01:44:49.694764: I external/tf_serving/tensorflow_serving/model_servers/server_core.cc:591]  (Re-)adding model: effv2b0\n",
      "2022-12-09 01:44:49.805917: I external/tf_serving/tensorflow_serving/core/basic_manager.cc:740] Successfully reserved resources to load servable {name: effv2b0 version: 1670550215}\n",
      "2022-12-09 01:44:49.805953: I external/tf_serving/tensorflow_serving/core/loader_harness.cc:66] Approving load for servable version {name: effv2b0 version: 1670550215}\n",
      "2022-12-09 01:44:49.805965: I external/tf_serving/tensorflow_serving/core/loader_harness.cc:74] Loading servable version {name: effv2b0 version: 1670550215}\n",
      "2022-12-09 01:44:49.806719: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:38] Reading SavedModel from: /models/effv2b0/1670550215\n",
      "2022-12-09 01:44:49.921127: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:90] Reading meta graph with tags { serve }\n",
      "2022-12-09 01:44:49.921156: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /models/effv2b0/1670550215\n",
      "2022-12-09 01:44:49.923787: I external/org_tensorflow/tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2022-12-09 01:44:50.192142: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:211] Restoring SavedModel bundle.\n",
      "2022-12-09 01:44:50.208213: W external/org_tensorflow/tensorflow/core/platform/profile_utils/cpu_utils.cc:87] Failed to get CPU frequency: -1\n",
      "2022-12-09 01:44:50.742739: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:195] Running initialization op on SavedModel bundle at path: /models/effv2b0/1670550215\n",
      "2022-12-09 01:44:50.860396: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:283] SavedModel load for tags { serve }; Status: success: OK. Took 1053677 microseconds.\n",
      "2022-12-09 01:44:50.880737: I external/tf_serving/tensorflow_serving/servables/tensorflow/saved_model_warmup_util.cc:59] No warmup data file found at /models/effv2b0/1670550215/assets.extra/tf_serving_warmup_requests\n",
      "2022-12-09 01:44:50.883234: I external/tf_serving/tensorflow_serving/core/loader_harness.cc:87] Successfully loaded servable version {name: effv2b0 version: 1670550215}\n",
      "2022-12-09 01:44:50.884784: I external/tf_serving/tensorflow_serving/model_servers/server_core.cc:486] Finished adding/updating models\n",
      "2022-12-09 01:44:50.884862: I external/tf_serving/tensorflow_serving/model_servers/server.cc:133] Using InsecureServerCredentials\n",
      "2022-12-09 01:44:50.884881: I external/tf_serving/tensorflow_serving/model_servers/server.cc:383] Profiler service is enabled\n",
      "2022-12-09 01:44:50.886291: I external/tf_serving/tensorflow_serving/model_servers/server.cc:409] Running gRPC ModelServer at 0.0.0.0:8500 ...\n",
      "[warn] getaddrinfo: address family for nodename not supported\n",
      "2022-12-09 01:44:50.888857: I external/tf_serving/tensorflow_serving/model_servers/server.cc:430] Exporting HTTP/REST API at:localhost:8501 ...\n",
      "[evhttp_server.cc : 245] NET_LOG: Entering the event loop ...\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "#docker pull tensorflow/serving\n",
    "# esse funciona\n",
    "!docker run --rm -p 8501:8501 \\\n",
    "        --name tfserving_effv2 \\\n",
    "        -v \"/Users/csamp/Documents/stack_ab/effv2b0:/models/effv2b0\" \\\n",
    "        -e MODEL_NAME=effv2b0 \\\n",
    "        emacski/tensorflow-serving:latest-linux_arm64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2877ce83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API endpoint can be accessed at http://localhost:8501. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "51b1dc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "def run_prediction(data,headers,endpoint):\n",
    "    json_response = requests.post(endpoint,data=data,headers=headers)\n",
    "    prediction = json.loads(json_response.text)\n",
    "    return (decode_predictions(np.array(preds), top=3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac884838",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(json_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b17d9f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('n09332890', 'lakeside', 0.2955897),\n",
       " ('n09421951', 'sandbar', 0.24374594),\n",
       " ('n01855672', 'goose', 0.10379495)]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint = 'http://localhost:8501/v1/models/effv2:predict'\n",
    "data = json.dumps({\"instances\": x.tolist()})\n",
    "headers = {\"content-type\": \"application/json\"}\n",
    "run_prediction(data,headers,endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5d6cdeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from https://cnvrg.io/how-to-serve-a-model-with-tensorflow/\n",
    "# another way: https://medium.com/analytics-vidhya/deploy-production-ready-keras-model-with-tensorflow-serving-and-docker-85615245a9ed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef57bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_response = requests.post('http://localhost:8501/v1/models/effv2:predict', data=data, headers=headers)\n",
    "predictions = json.loads(json_response.text)\n",
    "print('Predicted:', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a9c5a258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ran docker with\n",
    "# docker run -t --rm -p 8501:8501 \\\n",
    "#     -v \"/Users/csamp/Documents/stack_ab/vgg16/:/models/vgg16/\" \\\n",
    "#     -e MODEL_NAME=vgg16 \\\n",
    "#     emacski/tensorflow-serving:latest-linux_arm64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2218cb63",
   "metadata": {},
   "source": [
    "I ran docker with:\n",
    "\n",
    "`\n",
    "docker run -t --rm -p 8501:8501 \\\n",
    "    -v \"/Users/csamp/Documents/stack_ab/vgg16/:/models/vgg16/\" \\\n",
    "    -e MODEL_NAME=vgg16 \\\n",
    "    emacski/tensorflow-serving:latest-linux_arm64`\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982a135e",
   "metadata": {},
   "source": [
    "docker run -t --rm -p 8501:8501 \\ \n",
    "    --mount type=bind,source=/tmp/model_name/,target=/models/model_name/ \n",
    "    -e MODEL_NAME=model_name \\ \n",
    "    emacski/tensorflow-serving:latest-linux_arm64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "79fe1dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-09 01:49:20.549439: I external/tf_serving/tensorflow_serving/model_servers/server.cc:89] Building single TensorFlow model file config:  model_name: effv2b0 model_base_path: /models/effv2b0\n",
      "2022-12-09 01:49:20.549712: I external/tf_serving/tensorflow_serving/model_servers/server_core.cc:465] Adding/updating models.\n",
      "2022-12-09 01:49:20.549726: I external/tf_serving/tensorflow_serving/model_servers/server_core.cc:591]  (Re-)adding model: effv2b0\n",
      "2022-12-09 01:49:20.657382: I external/tf_serving/tensorflow_serving/core/basic_manager.cc:740] Successfully reserved resources to load servable {name: effv2b0 version: 1670550215}\n",
      "2022-12-09 01:49:20.657418: I external/tf_serving/tensorflow_serving/core/loader_harness.cc:66] Approving load for servable version {name: effv2b0 version: 1670550215}\n",
      "2022-12-09 01:49:20.657436: I external/tf_serving/tensorflow_serving/core/loader_harness.cc:74] Loading servable version {name: effv2b0 version: 1670550215}\n",
      "2022-12-09 01:49:20.657975: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:38] Reading SavedModel from: /models/effv2b0/1670550215\n",
      "2022-12-09 01:49:20.727255: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:90] Reading meta graph with tags { serve }\n",
      "2022-12-09 01:49:20.727306: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /models/effv2b0/1670550215\n",
      "2022-12-09 01:49:20.728910: I external/org_tensorflow/tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2022-12-09 01:49:20.869414: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:211] Restoring SavedModel bundle.\n",
      "2022-12-09 01:49:20.879750: W external/org_tensorflow/tensorflow/core/platform/profile_utils/cpu_utils.cc:87] Failed to get CPU frequency: -1\n",
      "2022-12-09 01:49:21.378351: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:195] Running initialization op on SavedModel bundle at path: /models/effv2b0/1670550215\n",
      "2022-12-09 01:49:21.484685: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:283] SavedModel load for tags { serve }; Status: success: OK. Took 826710 microseconds.\n",
      "2022-12-09 01:49:21.503962: I external/tf_serving/tensorflow_serving/servables/tensorflow/saved_model_warmup_util.cc:59] No warmup data file found at /models/effv2b0/1670550215/assets.extra/tf_serving_warmup_requests\n",
      "2022-12-09 01:49:21.506184: I external/tf_serving/tensorflow_serving/core/loader_harness.cc:87] Successfully loaded servable version {name: effv2b0 version: 1670550215}\n",
      "2022-12-09 01:49:21.507621: I external/tf_serving/tensorflow_serving/model_servers/server_core.cc:486] Finished adding/updating models\n",
      "2022-12-09 01:49:21.507702: I external/tf_serving/tensorflow_serving/model_servers/server.cc:133] Using InsecureServerCredentials\n",
      "2022-12-09 01:49:21.507715: I external/tf_serving/tensorflow_serving/model_servers/server.cc:383] Profiler service is enabled\n",
      "2022-12-09 01:49:21.508492: I external/tf_serving/tensorflow_serving/model_servers/server.cc:409] Running gRPC ModelServer at 0.0.0.0:8500 ...\n",
      "[warn] getaddrinfo: address family for nodename not supported\n",
      "2022-12-09 01:49:21.509302: I external/tf_serving/tensorflow_serving/model_servers/server.cc:430] Exporting HTTP/REST API at:localhost:8501 ...\n",
      "[evhttp_server.cc : 245] NET_LOG: Entering the event loop ...\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!docker run -t --rm -p 8501:8501 \\\n",
    "    -v \"/Users/csamp/Documents/stack_ab/effv2b0/:/models/effv2b0/\" \\\n",
    "    -e MODEL_NAME=effv2b0 \\\n",
    "    emacski/tensorflow-serving:latest-linux_arm64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a204e00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
