{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cc37f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docker pull emacski/tensorflow-serving:latest-linux_arm64\n",
    "# docker run -t --rm -p 8501:8501 --mount type=bind,source=/tmp/model_name/,target=/models/model_name/ -e MODEL_NAME=model_name emacski/tensorflow-serving:latest-linux_arm64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2cfc948",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!docker start #como iniciar da  linha de comando\n",
    "!open --background -a Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e4920968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Hello from Docker!\r\n",
      "This message shows that your installation appears to be working correctly.\r\n",
      "\r\n",
      "To generate this message, Docker took the following steps:\r\n",
      " 1. The Docker client contacted the Docker daemon.\r\n",
      " 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub.\r\n",
      "    (arm64v8)\r\n",
      " 3. The Docker daemon created a new container from that image which runs the\r\n",
      "    executable that produces the output you are currently reading.\r\n",
      " 4. The Docker daemon streamed that output to the Docker client, which sent it\r\n",
      "    to your terminal.\r\n",
      "\r\n",
      "To try something more ambitious, you can run an Ubuntu container with:\r\n",
      " $ docker run -it ubuntu bash\r\n",
      "\r\n",
      "Share images, automate workflows, and more with a free Docker ID:\r\n",
      " https://hub.docker.com/\r\n",
      "\r\n",
      "For more examples and ideas, visit:\r\n",
      " https://docs.docker.com/get-started/\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!docker run hello-world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ed32a020",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!docker pull tensorflow/serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b1ae65dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# esse funciona para quem n tem m1\n",
    "#!docker pull tensorflow/serving:latest-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b7cb2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9c16b820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "573f6b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.efficientnet_v2 import EfficientNetV2B0\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.efficientnet_v2 import preprocess_input, decode_predictions\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b59d1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b0.h5\n",
      "29403144/29403144 [==============================] - 40s 1us/step\n"
     ]
    }
   ],
   "source": [
    "model = EfficientNetV2B0(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5dbe59c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/csamp/Documents/stack_ab'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "444ef35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 77ms/step\n",
      "Predicted: [('n06596364', 'comic_book', 0.17904864), ('n03590841', \"jack-o'-lantern\", 0.066323765), ('n03291819', 'envelope', 0.039136156)]\n"
     ]
    }
   ],
   "source": [
    "img_path = 'tf_serving/lion.jpg'\n",
    "\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "preds = model.predict(x)\n",
    "# decode the results into a list of tuples (class, description, probability)\n",
    "# (one such list for each sample in the batch)\n",
    "\n",
    "print('Predicted:', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b511ce3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 91). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: effv2b0/1670445686/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: effv2b0/1670445686/assets\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "current_time = int(time.time())\n",
    "path = f\"effv2b0/{current_time}\"\n",
    "model.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5d588a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'effv2b0/1670445686'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cff6f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # how the folder should look like\n",
    "# ├── effv2b0\n",
    "# │ ├── 1670405165\n",
    "# │ │ ├── assets\n",
    "# │ │ ├── saved_model.pb\n",
    "# │ │ └── variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3966db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latest-linux_arm64: Pulling from emacski/tensorflow-serving\r\n",
      "Digest: sha256:37ae953d10a10f520fc7aca068c866f28a424894c47b1d06c8cec22e631e29be\r\n",
      "Status: Image is up to date for emacski/tensorflow-serving:latest-linux_arm64\r\n",
      "docker.io/emacski/tensorflow-serving:latest-linux_arm64\r\n"
     ]
    }
   ],
   "source": [
    "# esse funciona\n",
    "#!docker pull emacski/tensorflow-serving:latest-linux_arm64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8243eb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !docker run -t --rm -p 8501:8501 \\\n",
    "#     -v \"/Users/csamp/Documents/stack_ab/effv2b0/:/models/effv2b0/\" \\\n",
    "#     -e MODEL_NAME=effv2 \\\n",
    "#     emacski/tensorflow-serving:latest-linux_arm6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c5da3edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!docker run -p 8501:8501 --name tfserving_vgg16 --mount type=bind,source=vgg16/,target=vgg16/ -e MODEL_NAME=vgg16 -t tensorflow/serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d76863f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!docker run -p 8502:8502 --name ttfserving_vgg -v source=/Users/csamp/Documents/stack_ab/vgg16/,target=vgg16 -e MODEL_NAME=vgg16 -t emacski/tensorflow-serving:latest-linux_arm64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c1de367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/csamp/Documents/stack_ab'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "92aa4eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-07 20:31:25.278289: I external/tf_serving/tensorflow_serving/model_servers/server.cc:89] Building single TensorFlow model file config:  model_name: effv2b0 model_base_path: /models/effv2b0\n",
      "2022-12-07 20:31:25.278676: I external/tf_serving/tensorflow_serving/model_servers/server_core.cc:465] Adding/updating models.\n",
      "2022-12-07 20:31:25.278691: I external/tf_serving/tensorflow_serving/model_servers/server_core.cc:591]  (Re-)adding model: effv2b0\n",
      "2022-12-07 20:31:25.394043: I external/tf_serving/tensorflow_serving/core/basic_manager.cc:740] Successfully reserved resources to load servable {name: effv2b0 version: 1670405165}\n",
      "2022-12-07 20:31:25.394086: I external/tf_serving/tensorflow_serving/core/loader_harness.cc:66] Approving load for servable version {name: effv2b0 version: 1670405165}\n",
      "2022-12-07 20:31:25.394118: I external/tf_serving/tensorflow_serving/core/loader_harness.cc:74] Loading servable version {name: effv2b0 version: 1670405165}\n",
      "2022-12-07 20:31:25.394712: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:38] Reading SavedModel from: /models/effv2b0/1670405165\n",
      "2022-12-07 20:31:25.483705: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:90] Reading meta graph with tags { serve }\n",
      "2022-12-07 20:31:25.483737: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /models/effv2b0/1670405165\n",
      "2022-12-07 20:31:25.486871: I external/org_tensorflow/tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2022-12-07 20:31:25.771608: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:211] Restoring SavedModel bundle.\n",
      "2022-12-07 20:31:25.789369: W external/org_tensorflow/tensorflow/core/platform/profile_utils/cpu_utils.cc:87] Failed to get CPU frequency: -1\n",
      "2022-12-07 20:31:26.332259: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:195] Running initialization op on SavedModel bundle at path: /models/effv2b0/1670405165\n",
      "2022-12-07 20:31:26.419496: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:283] SavedModel load for tags { serve }; Status: success: OK. Took 1024783 microseconds.\n",
      "2022-12-07 20:31:26.439593: I external/tf_serving/tensorflow_serving/servables/tensorflow/saved_model_warmup_util.cc:59] No warmup data file found at /models/effv2b0/1670405165/assets.extra/tf_serving_warmup_requests\n",
      "2022-12-07 20:31:26.441698: I external/tf_serving/tensorflow_serving/core/loader_harness.cc:87] Successfully loaded servable version {name: effv2b0 version: 1670405165}\n",
      "2022-12-07 20:31:26.442396: I external/tf_serving/tensorflow_serving/model_servers/server_core.cc:486] Finished adding/updating models\n",
      "2022-12-07 20:31:26.442465: I external/tf_serving/tensorflow_serving/model_servers/server.cc:133] Using InsecureServerCredentials\n",
      "2022-12-07 20:31:26.442487: I external/tf_serving/tensorflow_serving/model_servers/server.cc:383] Profiler service is enabled\n",
      "2022-12-07 20:31:26.443730: I external/tf_serving/tensorflow_serving/model_servers/server.cc:409] Running gRPC ModelServer at 0.0.0.0:8500 ...\n",
      "[warn] getaddrinfo: address family for nodename not supported\n",
      "2022-12-07 20:31:26.446369: I external/tf_serving/tensorflow_serving/model_servers/server.cc:430] Exporting HTTP/REST API at:localhost:8501 ...\n",
      "[evhttp_server.cc : 245] NET_LOG: Entering the event loop ...\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "#docker pull tensorflow/serving\n",
    "# esse funciona\n",
    "!docker run --rm -p 8501:8501 \\\n",
    "        --name tfserving_effv2 \\\n",
    "        -v \"/Users/csamp/Documents/stack_ab/effv2b0:/models/effv2b0\" \\\n",
    "        -e MODEL_NAME=effv2b0 \\\n",
    "        emacski/tensorflow-serving:latest-linux_arm64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2877ce83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API endpoint can be accessed at http://localhost:8501. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "51b1dc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "def run_prediction(data,headers,endpoint):\n",
    "    json_response = requests.post(endpoint,data=data,headers=headers)\n",
    "    prediction = json.loads(json_response.text)\n",
    "    return (decode_predictions(np.array(preds), top=3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4bc6add3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'error': 'Servable not found for request: Latest(effv2)'}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(json_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b17d9f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('n06596364', 'comic_book', 0.17904864),\n",
       " ('n03590841', \"jack-o'-lantern\", 0.066323765),\n",
       " ('n03291819', 'envelope', 0.039136156)]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint = 'http://localhost:8501/v1/models/effv2:predict'\n",
    "data = json.dumps({\"instances\": x.tolist()})\n",
    "headers = {\"content-type\": \"application/json\"}\n",
    "run_prediction(data,headers,endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5d6cdeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from https://cnvrg.io/how-to-serve-a-model-with-tensorflow/\n",
    "# another way: https://medium.com/analytics-vidhya/deploy-production-ready-keras-model-with-tensorflow-serving-and-docker-85615245a9ed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6ef57bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [('n06596364', 'comic_book', 0.17904864), ('n03590841', \"jack-o'-lantern\", 0.066323765), ('n03291819', 'envelope', 0.039136156)]\n"
     ]
    }
   ],
   "source": [
    "json_response = requests.post('http://localhost:8501/v1/models/effv2:predict', data=data, headers=headers)\n",
    "predictions = json.loads(json_response.text)\n",
    "print('Predicted:', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a9c5a258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ran docker with\n",
    "# docker run -t --rm -p 8501:8501 \\\n",
    "#     -v \"/Users/csamp/Documents/stack_ab/vgg16/:/models/vgg16/\" \\\n",
    "#     -e MODEL_NAME=vgg16 \\\n",
    "#     emacski/tensorflow-serving:latest-linux_arm64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2218cb63",
   "metadata": {},
   "source": [
    "I ran docker with:\n",
    "\n",
    "`\n",
    "docker run -t --rm -p 8501:8501 \\\n",
    "    -v \"/Users/csamp/Documents/stack_ab/vgg16/:/models/vgg16/\" \\\n",
    "    -e MODEL_NAME=vgg16 \\\n",
    "    emacski/tensorflow-serving:latest-linux_arm6`\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982a135e",
   "metadata": {},
   "source": [
    "docker run -t --rm -p 8501:8501 \\ \n",
    "    --mount type=bind,source=/tmp/model_name/,target=/models/model_name/ \n",
    "    -e MODEL_NAME=model_name \\ \n",
    "    emacski/tensorflow-serving:latest-linux_arm64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79fe1dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker: Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?.\r\n",
      "See 'docker run --help'.\r\n"
     ]
    }
   ],
   "source": [
    "!docker run -t --rm -p 8501:8501 \\\n",
    "    -v \"/Users/csamp/Documents/stack_ab/effv2/:/models/effv2/\" \\\n",
    "    -e MODEL_NAME=vgg16 \\\n",
    "    emacski/tensorflow-serving:latest-linux_arm6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a0e18a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
