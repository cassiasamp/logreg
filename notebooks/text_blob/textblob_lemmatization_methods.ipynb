{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0de3fa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://textblob.readthedocs.io/en/dev/_modules/textblob/blob.html#Word.lemmatize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693b5cdd",
   "metadata": {},
   "source": [
    "Things To Consider In Utilizing Lemmatization\n",
    "\n",
    "1. It uses dictionary-based words. With the term lemma which means the root or base form of a word, lemmatization aims to provide the base form of a word rather than just removing the inflections of a word.\n",
    "2. It completely depends on parts of speech to find a base word. Without specifying the parts of speech), lemmatization might not perform well and you might not get the result that you’re looking for.\n",
    "3. It is slower than stemming but it’s more powerful. Since lemmatization doesn’t follow an algorithm to perform on words and the need of providing parts of speech, it is considered slower than stemming. However, it’s more powerful in a way that it uses dictionary-based words for results. \n",
    "4. It has higher accuracy in looking for the root word. As lemmatization uses dictionary-based words in laying out results from an inflected word, you’ll have higher chances of getting accurate outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "385c9e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in /Users/csamp/mambaforge/envs/todas-elas-env/lib/python3.9/site-packages (0.17.1)\r\n",
      "Requirement already satisfied: nltk>=3.1 in /Users/csamp/mambaforge/envs/todas-elas-env/lib/python3.9/site-packages (from textblob) (3.6.7)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/csamp/mambaforge/envs/todas-elas-env/lib/python3.9/site-packages (from nltk>=3.1->textblob) (2022.9.11)\r\n",
      "Requirement already satisfied: tqdm in /Users/csamp/mambaforge/envs/todas-elas-env/lib/python3.9/site-packages (from nltk>=3.1->textblob) (4.64.1)\r\n",
      "Requirement already satisfied: joblib in /Users/csamp/mambaforge/envs/todas-elas-env/lib/python3.9/site-packages (from nltk>=3.1->textblob) (1.1.0)\r\n",
      "Requirement already satisfied: click in /Users/csamp/mambaforge/envs/todas-elas-env/lib/python3.9/site-packages (from nltk>=3.1->textblob) (8.1.3)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9a9c64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de892320",
   "metadata": {},
   "source": [
    "# 1 - lemmatization is different from stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f494f23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemmatization: ['According', 'to', 'the', 'zen', 'of', 'Python', 'simple', 'code', 'are', 'better', 'than', 'complex', 'code']\n",
      "stemming: ['accord', 'to', 'the', 'zen', 'of', 'python', 'simpl', 'code', 'are', 'better', 'than', 'complex', 'code']\n"
     ]
    }
   ],
   "source": [
    "example = TextBlob(\"According to the zen of Python, simple codes are better than complex codes.\") # mostrar mais de um exemplo\n",
    "# com textao\n",
    "\n",
    "# lemmatization\n",
    "print('lemmatization:', example.words.lemmatize())\n",
    "# stemming\n",
    "print('stemming:', example.words.stem())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c616bfc3",
   "metadata": {},
   "source": [
    "# 2 - lemmatization depends on POS, with bad POS, it might not perform well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7c7e54f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = TextBlob(\"Simple codes are better than complex codes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363adb9a",
   "metadata": {},
   "source": [
    "CC coordinating conjunction\n",
    "CD cardinal digit\n",
    "DT determiner\n",
    "EX existential there (like: “there is” … think of it like “there exists”)\n",
    "FW foreign word\n",
    "IN preposition/subordinating conjunction\n",
    "JJ adjective ‘big’\n",
    "JJR adjective, comparative ‘bigger’\n",
    "JJS adjective, superlative ‘biggest’\n",
    "LS list marker 1)\n",
    "MD modal could, will\n",
    "NN noun, singular ‘desk’\n",
    "NNS noun plural ‘desks’\n",
    "NNP proper noun, singular ‘Harrison’\n",
    "NNPS proper noun, plural ‘Americans’\n",
    "PDT predeterminer ‘all the kids’\n",
    "POS possessive ending parent‘s\n",
    "PRP personal pronoun I, he, she\n",
    "PRP$ possessive pronoun my, his, hers\n",
    "RB adverb very, silently,\n",
    "RBR adverb, comparative better\n",
    "RBS adverb, superlative best\n",
    "RP particle give up\n",
    "TO to go ‘to‘ the store.\n",
    "UH interjection errrrrrrrm\n",
    "VB verb, base form take\n",
    "VBD verb, past tense took\n",
    "VBG verb, gerund/present participle taking\n",
    "VBN verb, past participle taken\n",
    "VBP verb, sing. present, non-3d take\n",
    "VBZ verb, 3rd person sing. present takes\n",
    "WDT wh-determiner which\n",
    "WP wh-pronoun who, what\n",
    "WP$ possessive wh-pronoun whose\n",
    "WRB wh-adverb where, when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f2af8f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['This', 'is', 'a', 'complete', 'sentence'])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_example = TextBlob('This is a complete sentence')\n",
    "sentence_example.words.lemmatize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "de52c9b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('This', 'DT'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('complete', 'JJ'),\n",
       " ('sentence', 'NN')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_example.tags\n",
    "# dt - determiner\n",
    "# vbz - verb, 3rd person singular\n",
    "# jj - adjective\n",
    "# nn - noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a7d418b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemma with pos tag: be\n",
      "lemma without pos tag: is\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "print('lemma with pos tag:', wnl.lemmatize('is', 'v'))\n",
    "print('lemma without pos tag:', wnl.lemmatize('is'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "52d590e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('According', 'VBG'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('zen', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('Python', 'NNP'),\n",
       " ('simple', 'JJ'),\n",
       " ('codes', 'NNS'),\n",
       " ('are', 'VBP'),\n",
       " ('better', 'JJR'),\n",
       " ('than', 'IN'),\n",
       " ('complex', 'JJ'),\n",
       " ('codes', 'NNS')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example.tags \n",
    "# vbg - verb, gerund/ present participle\n",
    "# to - to\n",
    "# dt - determiner\n",
    "# nn - noun\n",
    "# nnp - proper noun\n",
    "# jj - adjective\n",
    "# nns - noun plural\n",
    "# vbp - verb, singular present\n",
    "# jjr - adjective comparative\n",
    "# in - preposition / subordinating conjunction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2228558d",
   "metadata": {},
   "source": [
    "# 3 - Lemmatization is slower than stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "23913158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0.0005240440368652344\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_lemma = time.time()\n",
    "example.words.lemmatize()\n",
    "end_lemma = time.time()\n",
    "elapsed_lemma = end_lemma - start_lemma\n",
    "print('Elapsed time:', elapsed_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f6ae4efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0.0008702278137207031\n"
     ]
    }
   ],
   "source": [
    "start_stem = time.time()\n",
    "example.words.stem()\n",
    "end_stem = time.time()\n",
    "elapsed_stem = end_stem - start_stem\n",
    "print('Elapsed time:', elapsed_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "056ec626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elapsed_lemma > elapsed_stem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc8d2c6",
   "metadata": {},
   "source": [
    "# 4 - Lemmatization has higher accuracy\n",
    "\n",
    "Accuracy: Lemmatization does not merely cut words off as you see in stemming algorithms. Analysis of words is conducted based on the word’s POS to take context into consideration when producing lemmas. Also, lemmatization leads to real dictionary words being produced.\n",
    "\n",
    "Here you can see some of the output words are not part of the english dictionary (i.e., “becaus,” “people,” and “programm.”). Another thing to notice is that context is not taken into consideration. For instance, “programmers” is a plural noun but it was reduced down to “program,” which can be a noun or a verb – in other words, the root words are ambiguous.\n",
    "\n",
    "The motivation behind context-sensitive lemmatizers was to improve the performance on unseen and ambiguous words. In our lemmatization example, we will be using a popular lemmatizer called WordNet lemmatizer. \n",
    "\n",
    "Wordnet is a large, free, and publicly available lexical database for the English language aiming to establish structured semantic relationships between words.\n",
    "\n",
    "Input words passed to our lemmatizer will remain unchanged if it cannot be found in WordNet. This means context must be provided, which is done by giving the value for the part-of-speech parameter,  pos, in wordnet_lemmatizer.lemmatize.\n",
    "\n",
    "Notice the word “programmer” were not cut down to “program” by our lemmatizer: this is because we told our lemmatizer to only stem verbs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57753ad",
   "metadata": {},
   "source": [
    "-> Text preprocessing includes both Stemming as well as Lemmatization. Many times people find these two terms confusing. Some treat these two as the same. Actually, lemmatization is preferred over Stemming because lemmatization does morphological analysis of the words.\n",
    "\n",
    "0. https://textblob.readthedocs.io/en/dev/_modules/textblob/blob.html#Word.lemmatize \n",
    "\n",
    "basear topicos nos metodos da documentacao\n",
    "\n",
    "1. https://www.alura.com.br/artigos/textblob-alternativa-para-processamento-linguagem-natural - done\n",
    "2. https://www.geeksforgeeks.org/python-lemmatization-with-textblob/ - done\n",
    "3. https://stackabuse.com/python-for-nlp-introduction-to-the-textblob-library/ - done\n",
    "4. https://hannibunny.github.io/nlpbook/02normalisation/03StemLemma.html - done\n",
    "5. https://www.analyticsvidhya.com/blog/2021/10/making-natural-language-processing-easy-with-textblob/ - done\n",
    "6. https://textblob.readthedocs.io/en/dev/quickstart.html - done\n",
    "7. https://www.machinelearningplus.com/nlp/lemmatization-examples-python/ - done\n",
    "8. https://blog.enterprisedna.co/lemmatization-in-python-a-beginners-guide/ - done\n",
    "9. https://acervolima.com/python-abordagens-de-lematizacao-com-exemplos/ - done\n",
    "10. https://www.guru99.com/stemming-lemmatization-python-nltk.html - done\n",
    "11. Wordnet: https://wordnet.princeton.edu/\n",
    "\n",
    "-- perguntar novamente qual a ideia -- apresentar duas outlines e ver qual ele acha\n",
    "\n",
    "- outline 1: stem vs lemma\n",
    "- outline 2: todas as func da text blob -- esse\n",
    "- outline 3: lemma como parte de um projeto maior - pesquisar tf-idf, LDA e topic modelling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5500568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /Users/csamp/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/csamp/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/csamp/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/csamp/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package conll2000 to /Users/csamp/nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /Users/csamp/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "!python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d9a437",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
