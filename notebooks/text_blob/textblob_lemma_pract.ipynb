{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c29ef880",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install textblob\n",
    "#!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa4d861c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/csamp/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/csamp/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /Users/csamp/nltk_data...\n",
      "[nltk_data] Downloading package brown to /Users/csamp/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/brown.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc632c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5ce357e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = textblob.TextBlob(\"hi, I am Madeleine! I really like hot lamen.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "91de1eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"hi, i am madeleine! i really like hot lamen.\")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9febeb1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"HI, I AM MADELEINE! I REALLY LIKE HOT LAMEN.\")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f86e796b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['hi', ',', 'I', 'am', 'Madeleine', '!', 'I', 'really', 'like', 'hot', 'lamen', '.'])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example.tokenize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c37f7eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"hi, I am Madeleine!\"), Sentence(\"I really like hot lamen.\")]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example.sentences # identifica quando tem espaco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e359355f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['hi', 'I', 'am', 'Madeleine', 'I', 'really', 'like', 'hot', 'lamen'])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c283c54f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['madeleine', 'hot lamen'])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example.noun_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f5c20b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hi', 'NN'),\n",
       " ('I', 'PRP'),\n",
       " ('am', 'VBP'),\n",
       " ('Madeleine', 'JJ'),\n",
       " ('I', 'PRP'),\n",
       " ('really', 'RB'),\n",
       " ('like', 'IN'),\n",
       " ('hot', 'JJ'),\n",
       " ('lamen', 'NNS')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4dd29e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.guru99.com/pos-tagging-chunking-nltk.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bd4ce2",
   "metadata": {},
   "source": [
    "### tabela pos tag\n",
    "| Abbreviation | Meaning                                              |\n",
    "| ------------ | ---------------------------------------------------- |\n",
    "| CC           | coordinating conjunction                             |\n",
    "| CD           | cardinal digit                                       |\n",
    "| DT           | determiner                                           |\n",
    "| EX           | existential there                                    |\n",
    "| FW           | foreign word                                         |\n",
    "| IN           | preposition/subordinating conjunction                |\n",
    "| JJ           | This NLTK POS Tag is an adjective (large)            |\n",
    "| JJR          | adjective, comparative (larger)                      |\n",
    "| JJS          | adjective, superlative (largest)                     |\n",
    "| LS           | list market                                          |\n",
    "| MD           | modal (could, will)                                  |\n",
    "| NN           | noun, singular (cat, tree)                           |\n",
    "| NNS          | noun plural (desks)                                  |\n",
    "| NNP          | proper noun, singular (sarah)                        |\n",
    "| NNPS         | proper noun, plural (indians or americans)           |\n",
    "| PDT          | predeterminer (all, both, half)                      |\n",
    "| POS          | possessive ending (parent\\\\ ‘s)                      |\n",
    "| PRP          | personal pronoun (hers, herself, him, himself)       |\n",
    "| PRP$         | possessive pronoun (her, his, mine, my, our )        |\n",
    "| RB           | adverb (occasionally, swiftly)                       |\n",
    "| RBR          | adverb, comparative (greater)                        |\n",
    "| RBS          | adverb, superlative (biggest)                        |\n",
    "| RP           | particle (about)                                     |\n",
    "| TO           | infinite marker (to)                                 |\n",
    "| UH           | interjection (goodbye)                               |\n",
    "| VB           | verb (ask)                                           |\n",
    "| VBG          | verb gerund (judging)                                |\n",
    "| VBD          | verb past tense (pleaded)                            |\n",
    "| VBN          | verb past participle (reunified)                     |\n",
    "| VBP          | verb, present tense not 3rd person singular(wrap)    |\n",
    "| VBZ          | verb, present tense with 3rd person singular (bases) |\n",
    "| WDT          | wh-determiner (that, what)                           |\n",
    "| WP           | wh- pronoun (who)                                    |\n",
    "| WRB          | wh- adverb (how)                                     |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6fed19",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc477c2",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a5c51769",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to /Users/csamp/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8900bc11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi', 'I', 'am', 'Madeleine', 'I', 'really', 'like', 'hot', 'lamen']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized = [word.lemmatize() for word in example.words]\n",
    "lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "22f9588f",
   "metadata": {},
   "outputs": [],
   "source": [
    "example2 = textblob.TextBlob(\"I like traveling between worlds. When I see the Earth, there is love in how nature makes things.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cbfaac39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['I', 'like', 'traveling', 'between', 'worlds', 'When', 'I', 'see', 'the', 'Earth', 'there', 'is', 'love', 'in', 'how', 'nature', 'makes', 'things'])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example2.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2274bef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'like',\n",
       " 'traveling',\n",
       " 'between',\n",
       " 'world',\n",
       " 'When',\n",
       " 'I',\n",
       " 'see',\n",
       " 'the',\n",
       " 'Earth',\n",
       " 'there',\n",
       " 'is',\n",
       " 'love',\n",
       " 'in',\n",
       " 'how',\n",
       " 'nature',\n",
       " 'make',\n",
       " 'thing']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[word.lemmatize() for word in example2.words]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bca8fb",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c38c5a",
   "metadata": {},
   "source": [
    "### Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8e83bf2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.225, subjectivity=0.525)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example.sentiment\n",
    "# polarity neg -1 --- pos +1\n",
    "# objectivity 0 --- subjectivity 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ffe5ce04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.5, subjectivity=0.6)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example2.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "aab755e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "example3 = textblob.TextBlob(\"I hate everything about earth and ramen!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "be0a7a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=-1.0, subjectivity=0.9)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example3.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b60c2223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=-1.0, subjectivity=0.9, assessments=[(['hate', '!'], -1.0, 0.9, None)])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example3.sentiment_assessments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "deebc3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use of lemmatization along with word vectors, tf-idf, LDA for topic modelling\n",
    "# confers more precision when eliminationg plurals and using synonyms\n",
    "# a diferenca para stemming eh que o segundo pode chegar em algo que nao existe -- para busca, tudo bem, por exemplo\n",
    "# em analise, nem tanto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5af506ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatization is slower as it knows the context of words before processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf5ceea",
   "metadata": {},
   "source": [
    "What is Lemmatization?\n",
    "Lemmatization in NLTK is the algorithmic process of finding the lemma of a word depending on its meaning and context. Lemmatization usually refers to the morphological analysis of words, which aims to remove inflectional endings. It helps in returning the base or dictionary form of a word known as the lemma.\n",
    "\n",
    "The NLTK Lemmatization method is based on WorldNet’s built-in morph function. Text preprocessing includes both stemming as well as lemmatization. Many people find the two terms confusing. Some treat these as the same, but there is a difference between stemming vs lemmatization. Lemmatization is preferred over the former because of the below reason.\n",
    "\n",
    "Lemmatizer minimizes text ambiguity. Example words like bicycle or bicycles are converted to base word bicycle. Basically, it will convert all words having the same meaning but different representation to their base form. It reduces the word density in the given text and helps in preparing the accurate features for training machine. Cleaner the data, the more intelligent and accurate your machine learning model, will be. NLTK Lemmatizer will also saves memory as well as computational cost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37333a1d",
   "metadata": {},
   "source": [
    "textblob uses wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "32916967",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatize(**kwargs)[source]\n",
    "#Return the lemma for a word using WordNet’s morphy function.\n",
    "#Parameters:\tpos – Part of speech to filter upon. If None, defaults to _wordnet.NOUN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "48c3e627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://textblob.readthedocs.io/en/dev/_modules/textblob/blob.html#Word.lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3df51367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go\n",
      "go\n",
      "go\n"
     ]
    }
   ],
   "source": [
    "print(textblob.TextBlob(\"went\").words[0].lemmatize(\"v\")) # mode \"v\" for verb\n",
    "print(textblob.TextBlob(\"gone\").words[0].lemmatize(\"v\"))\n",
    "print(textblob.TextBlob(\"going\").words[0].lemmatize(\"v\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "54d556d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bought\n"
     ]
    }
   ],
   "source": [
    "print(textblob.TextBlob(\"bought\").words[0].lemmatize())#(\"v\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "dc1bbc88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buy\n"
     ]
    }
   ],
   "source": [
    "print(textblob.TextBlob(\"bought\").words[0].lemmatize(\"v\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "aa57cc9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "late\n",
      "pretty\n",
      "bad\n"
     ]
    }
   ],
   "source": [
    "print(textblob.TextBlob(\"later\").words[0].lemmatize(\"a\")) # mode \"a\" for adverb/adjective\n",
    "print(textblob.TextBlob(\"prettier\").words[0].lemmatize(\"a\"))\n",
    "print(textblob.TextBlob(\"worse\").words[0].lemmatize(\"a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a1de515a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "woman\n"
     ]
    }
   ],
   "source": [
    "print(textblob.TextBlob(\"women\").words[0].lemmatize(\"n\")) # mode \"n\" for noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "10d0383d",
   "metadata": {},
   "outputs": [],
   "source": [
    "myBlob3=textblob.TextBlob(\"The engineer went into the garden and found the cats lying beneath the trees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "13d8bb40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The The\n",
      "engineer engineer\n",
      "went go\n",
      "into into\n",
      "the the\n",
      "garden garden\n",
      "and and\n",
      "found find\n",
      "the the\n",
      "cats cat\n",
      "lying lie\n",
      "beneath beneath\n",
      "the the\n",
      "trees tree\n"
     ]
    }
   ],
   "source": [
    "for word in myBlob3.words:\n",
    "    print(word, word.lemmatize(\"v\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "60569264",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install textblob-de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "00a9b4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textblob_de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6b92a41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "myBlob5=textblob_de.TextBlobDE(\"Er ist mit seinen Katzen über drei Tische gesprungen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "bcfb6e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Er ist mit seinen Katzen über drei Tische gesprungen\n"
     ]
    }
   ],
   "source": [
    "for s in myBlob5.sentences:\n",
    "    print(\"-\"*20)\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "03433f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Er PRP\n",
      "ist VBN\n",
      "mit IN\n",
      "seinen PRP$\n",
      "Katzen NNS\n",
      "über IN\n",
      "drei CD\n",
      "Tische JJ\n",
      "gesprungen VBN\n"
     ]
    }
   ],
   "source": [
    "for word,tag in myBlob5.tags:\n",
    "    print(word, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "57a45a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "er\n",
      "sein\n",
      "mit\n",
      "seinen\n",
      "Katze\n",
      "über\n",
      "drei\n",
      "Tisch\n",
      "gesprungen\n"
     ]
    }
   ],
   "source": [
    "for word in myBlob5.words.lemmatize():\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a44b9e4",
   "metadata": {},
   "source": [
    "Also, sometimes, the same word can have multiple different ‘lemma’s. So, based on the context it’s used, you should identify the ‘part-of-speech’ (POS) tag for the word in that specific context and extract the appropriate lemma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1723d835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The striped bat be hang on their foot for best'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define function to lemmatize each word with its POS tag\n",
    "def lemmatize_with_postag(sentence):\n",
    "    sent = textblob.TextBlob(sentence)\n",
    "    tag_dict = {\"J\": 'a', \n",
    "                \"N\": 'n', \n",
    "                \"V\": 'v', \n",
    "                \"R\": 'r'}\n",
    "    words_and_tags = [(w, tag_dict.get(pos[0], 'n')) for w, pos in sent.tags]    \n",
    "    lemmatized_list = [wd.lemmatize(tag) for wd, tag in words_and_tags]\n",
    "    return \" \".join(lemmatized_list)\n",
    "\n",
    "# Lemmatize\n",
    "sentence = \"The striped bats are hanging on their feet for best\"\n",
    "lemmatize_with_postag(sentence)\n",
    "#> 'The striped bat be hang on their foot for best'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a1f4cf",
   "metadata": {},
   "source": [
    "Things To Consider In Utilizing Lemmatization\n",
    "\n",
    "- It uses dictionary-based words. With the term lemma which means the root or base form of a word, lemmatization aims to provide the base form of a word rather than just removing the inflections of a word.\n",
    "- It completely depends on parts of speech to find a base word. Without specifying the parts of speech), lemmatization might not perform well and you might not get the result that you’re looking for.\n",
    "- It is slower than stemming but it’s more powerful. Since lemmatization doesn’t follow an algorithm to perform on words and the need of providing parts of speech, it is considered slower than stemming. However, it’s more powerful in a way that it uses dictionary-based words for results. \n",
    "- It has higher accuracy in looking for the root word. As lemmatization uses dictionary-based words in laying out results from an inflected word, you’ll have higher chances of getting accurate outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05491b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
